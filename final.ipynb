{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for handling transaction\n",
    "import joblib \n",
    "from solcx import install_solc, compile_source\n",
    "#Specific Solidity version harhat works well with / there is more documentation for\n",
    "install_solc('0.8.0')\n",
    "from solcx import set_solc_version\n",
    "set_solc_version('0.8.0')\n",
    "from solcx import compile_source\n",
    "from web3 import Web3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    data = pd.read_csv('transactions.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'transactions.csv' was not found.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preview:\n",
      "   Unnamed: 0  accountNumber  customerId  creditLimit  availableMoney  \\\n",
      "0           0      737265056   737265056         5000          5000.0   \n",
      "1           1      737265056   737265056         5000          5000.0   \n",
      "2           2      737265056   737265056         5000          5000.0   \n",
      "3           3      737265056   737265056         5000          5000.0   \n",
      "4           4      830329091   830329091         5000          5000.0   \n",
      "\n",
      "   transactionDateTime  transactionAmount         merchantName acqCountry  \\\n",
      "0  2016-08-13T14:27:32              98.55                 Uber         US   \n",
      "1  2016-10-11T05:05:54              74.51          AMC #191138         US   \n",
      "2  2016-11-08T09:18:39               7.47           Play Store         US   \n",
      "3  2016-12-10T02:14:50               7.47           Play Store         US   \n",
      "4  2016-03-24T21:04:46              71.18  Tim Hortons #947751         US   \n",
      "\n",
      "  merchantCountryCode  ...  echoBuffer  currentBalance merchantCity  \\\n",
      "0                  US  ...         NaN             0.0          NaN   \n",
      "1                  US  ...         NaN             0.0          NaN   \n",
      "2                  US  ...         NaN             0.0          NaN   \n",
      "3                  US  ...         NaN             0.0          NaN   \n",
      "4                  US  ...         NaN             0.0          NaN   \n",
      "\n",
      "  merchantState merchantZip cardPresent  posOnPremises  recurringAuthInd  \\\n",
      "0           NaN         NaN       False            NaN               NaN   \n",
      "1           NaN         NaN        True            NaN               NaN   \n",
      "2           NaN         NaN       False            NaN               NaN   \n",
      "3           NaN         NaN       False            NaN               NaN   \n",
      "4           NaN         NaN        True            NaN               NaN   \n",
      "\n",
      "   expirationDateKeyInMatch isFraud  \n",
      "0                     False   False  \n",
      "1                     False   False  \n",
      "2                     False   False  \n",
      "3                     False   False  \n",
      "4                     False   False  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preview data\n",
    "print(\"Data Preview:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to dynamically set features\n",
    "# choose from any column in the dataset\n",
    "selected_features = ['creditLimit', 'availableMoney', 'transactionAmount', 'expirationDateKeyInMatch', 'cardPresent']\n",
    "def update_features(new_features):\n",
    "    global selected_features\n",
    "    selected_features = new_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the target variable\n",
    "target = 'isFraud'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure non-negative values in X and handle NaN values\n",
    "# some later function used do not work with negative values and NaN values\n",
    "X = data[selected_features].apply(lambda x: np.maximum(x, 0)).fillna(0)\n",
    "# Converts the target column values into binary integers (1 or 0).\n",
    "y = data[target].apply(lambda x: 1 if str(x).strip().upper() == 'TRUE' else 0).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected Features after SelectKBest:\n",
      "Index(['creditLimit', 'availableMoney', 'transactionAmount',\n",
      "       'expirationDateKeyInMatch', 'cardPresent'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "\n",
    "# Select the top 5 features based on the chi-squared statistical test\n",
    "selector = SelectKBest(chi2, k=5)\n",
    "# Fit the selector to the data and transform the features\n",
    "X_new = selector.fit_transform(X, y)\n",
    "# Get the names of the selected features\n",
    "selected_features = X.columns[selector.get_support(indices=True)]\n",
    "# Print the selected features\n",
    "print(\"\\nSelected Features after SelectKBest:\")\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data into training and testing sets\n",
    "def split_data(test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "        test_size (float): The proportion of the dataset to include in the test split. Default is 0.2 (20%).\n",
    "        random_state (int): Controls the shuffling applied to the data before splitting. Ensures reproducibility when set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Training and testing sets for features (X) and target (y).\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle Continuous Variables\n",
    "# Discretize continuous features into ordinal bins\n",
    "# When training, some columns were split into multiple columns so this helped brought them back together\n",
    "kbins = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the Target Variable\n",
    "# Apply SMOTE to balance the dataset by generating synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_hyperparameters(X_resampled, y_resampled):\n",
    "    \"\"\"\n",
    "    Performs hyperparameter tuning using GridSearchCV on the resampled training data.\n",
    "    \n",
    "    Parameters:\n",
    "        X_resampled: The resampled feature data.\n",
    "        y_resampled: The resampled target data.\n",
    "    \n",
    "    Returns:\n",
    "        The best DecisionTreeClassifier model with optimal parameters.\n",
    "    \"\"\"\n",
    "    # Define the parameter grid to search over\n",
    "    param_grid = {\n",
    "        'max_depth': [3, 5, 10],  # Maximum depth of the tree\n",
    "        'min_samples_split': [10, 20, 50],  # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [5, 10, 20]  # Minimum number of samples required to be at a leaf node\n",
    "    }\n",
    "    \n",
    "    # Set up the GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=DecisionTreeClassifier(random_state=42),  # The model to be optimized, use a consistent random state  for \n",
    "        param_grid=param_grid,  # The parameter grid to search over\n",
    "        cv=5,  # Number of cross-validation folds\n",
    "        scoring='f1',  # Optimize for F1 score to balance precision and recall\n",
    "        n_jobs=-1,  # Use all available CPU cores\n",
    "        verbose=2  # Verbosity level for logging\n",
    "    )\n",
    "    \n",
    "    # Fit the GridSearchCV object to the resampled data\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Print the best parameters and the best cross-validated F1 score\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best Cross-Validated F1 Score:\", grid_search.best_score_)\n",
    "    \n",
    "    # Return the best estimator (model) found by GridSearchCV\n",
    "    return grid_search.best_estimator_\n",
    "    #print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Update the train_and_evaluate function to use the tuned model\n",
    "def train_and_evaluate_with_tuning(test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = split_data(test_size, random_state)\n",
    "    \n",
    "    # Apply KBinsDiscretizer to transactionAmount\n",
    "    X_train.iloc[:, 2] = kbins.fit_transform(X_train.iloc[:, 2].values.reshape(-1, 1)).flatten()\n",
    "    X_test.iloc[:, 2] = kbins.transform(X_test.iloc[:, 2].values.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Balance the Target Variable\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Tune hyperparameters on the resampled training data\n",
    "    dt_classifier = tune_hyperparameters(X_resampled, y_resampled)\n",
    "    # dt_classifier = DecisionTreeClassifier(class_weight={0: 1, 1: 3}, random_state=42)\n",
    "\n",
    "\n",
    "    # Evaluate the tuned model on the test set\n",
    "    y_pred = dt_classifier.predict(X_test)\n",
    "    print(\"\\nModel Evaluation After Tuning:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Visualize confusion matrix with seaborn\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Fraud', 'Fraud'], yticklabels=['Not Fraud', 'Fraud'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize the decision tree\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(best_model, feature_names=X_train.columns, class_names=['Not Fraud', 'Fraud'], filled=True)\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize the decision tree\n",
    "    # plt.figure(figsize=(20, 10))\n",
    "    # plot_tree(dt_classifier, feature_names=selected_features, class_names=['Not Fraud', 'Fraud'], filled=True)\n",
    "    # plt.show()\n",
    "\n",
    "    return dt_classifier#, X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to explain the decision tree\n",
    "def explain_decision_tree(model):\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    for feature, importance in zip(selected_features, model.feature_importances_):\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "    print(\"\\nExample Decision Path Explanation:\")\n",
    "    from sklearn.tree import export_text\n",
    "    tree_rules = export_text(model, feature_names=selected_features)\n",
    "    print(tree_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 1245, in dump\n    return super().dump(obj)\n           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 451, in __call__\n    for dumped_filename in dump(a, filename):\n                           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 553, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\pickle.py\", line 487, in dump\n    self.save(obj)\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 352, in save\n    wrapper.write_array(obj, self)\n  File \"c:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 134, in write_array\n    pickler.file_handle.write(chunk.tobytes('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m update_features([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreditLimit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavailableMoney\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransactionAmount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpirationDateKeyInMatch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcardPresent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# train_and_evaluate(test_size=0.3, random_state=42)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dt_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_with_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 55\u001b[0m, in \u001b[0;36mtrain_and_evaluate_with_tuning\u001b[1;34m(test_size, random_state)\u001b[0m\n\u001b[0;32m     52\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Tune hyperparameters on the resampled training data\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m dt_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtune_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# dt_classifier = DecisionTreeClassifier(class_weight={0: 1, 1: 3}, random_state=42)\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Evaluate the tuned model on the test set\u001b[39;00m\n\u001b[0;32m     60\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m dt_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m, in \u001b[0;36mtune_hyperparameters\u001b[1;34m(X_resampled, y_resampled)\u001b[0m\n\u001b[0;32m     22\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     23\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mDecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),  \u001b[38;5;66;03m# The model to be optimized, use a consistent random state  for \u001b[39;00m\n\u001b[0;32m     24\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,  \u001b[38;5;66;03m# The parameter grid to search over\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Verbosity level for logging\u001b[39;00m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Fit the GridSearchCV object to the resampled data\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_resampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Print the best parameters and the best cross-validated F1 score\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\josma\\anaconda3\\envs\\AgentTester\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "\n",
    "# Example Usage\n",
    "update_features(['creditLimit', 'availableMoney', 'transactionAmount', 'expirationDateKeyInMatch', 'cardPresent'])\n",
    "# train_and_evaluate(test_size=0.3, random_state=42)\n",
    "dt_classifier = train_and_evaluate_with_tuning(test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#import joblib  # Import joblib to save and load models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save the trained Decision Tree model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfraud_detection_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Define the filename\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mdt_classifier\u001b[49m, model_filename)  \u001b[38;5;66;03m# Save the model to a .pkl file\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "#import joblib  # Import joblib to save and load models\n",
    "\n",
    "# Save the trained Decision Tree model\n",
    "model_filename = 'fraud_detection_model.pkl'  # Define the filename\n",
    "joblib.dump(dt_classifier, model_filename)  # Save the model to a .pkl file\n",
    "print(f\"\\nModel saved as {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(TP = True Positive, FP = False Positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision = TP/(TP+FP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall = TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparam_grid = {\\n    \\'max_depth\\': [3, 5, 10],\\n    \\'min_samples_split\\': [10, 20, 50],\\n    \\'min_samples_leaf\\': [5, 10, 20]\\n}\\ngrid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring=\\'f1\\')\\ngrid_search.fit(X_resampled, y_resampled)\\nbest_params = grid_search.best_params_\\nprint(\"Best Parameters:\", best_params)\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "'''\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [10, 20, 50],\n",
    "    'min_samples_leaf': [5, 10, 20]\n",
    "}\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='f1')\n",
    "grid_search.fit(X_resampled, y_resampled)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained Decision Tree model\n",
    "model_filename = 'fraud_detection_model.pkl'  # Define the filename\n",
    "joblib.dump(dt_classifier, model_filename)  # Save the model to a .pkl file\n",
    "print(f\"\\nModel saved as {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install web3 py-solc-x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile contract\n",
    "contract_source = '''\n",
    "// SPDX-License-Identifier: MIT\n",
    "pragma solidity ^0.8.0;\n",
    "\n",
    "contract Escrow {\n",
    "    address public payer;\n",
    "    address public payee;\n",
    "    uint public amount;\n",
    "    bool public isFraudulent;\n",
    "\n",
    "    constructor(address _payee) payable {\n",
    "        payer = msg.sender;\n",
    "        payee = _payee;\n",
    "        amount = msg.value;\n",
    "        isFraudulent = false;\n",
    "    }\n",
    "\n",
    "    function reportFraud() public {\n",
    "        require(msg.sender == payer, \"Only payer can report fraud\");\n",
    "        isFraudulent = true;\n",
    "    }\n",
    "\n",
    "    function releaseFunds() public {\n",
    "        require(!isFraudulent, \"Transaction flagged as fraudulent\");\n",
    "        require(msg.sender == payer, \"Only payer can release funds\");\n",
    "        payable(payee).transfer(amount);\n",
    "    }\n",
    "\n",
    "    function refund() public {\n",
    "        require(isFraudulent, \"Transaction not flagged as fraudulent\");\n",
    "        require(msg.sender == payer, \"Only payer can refund\");\n",
    "        payable(payer).transfer(amount);\n",
    "    }\n",
    "}\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the contract\n",
    "compiled_sol = compile_source(contract_source)\n",
    "#Compiles the Solidity contract (contract_source) into bytecode and an ABI (Application Binary Interface).\n",
    "\n",
    "\n",
    "# Extract the ABI and bytecode\n",
    "contract_interface = compiled_sol['<stdin>:Escrow']\n",
    "\n",
    "# Print the contract interface for debugging\n",
    "print(\"Contract Interface:\", contract_interface)\n",
    "#ontract_interface: Extracts the compiled contract's ABI and bytecode, which are required for deploying and interacting with the smart contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Hardhat network\n",
    "w3 = Web3(Web3.HTTPProvider('http://127.0.0.1:8545'))\n",
    "#Connects to the local Ethereum blockchain (running on Hardhat at 127.0.0.1:8545).\n",
    "\n",
    "# Verify the connection\n",
    "if w3.is_connected():\n",
    "    print(\"Connected to Hardhat network\")\n",
    "else:\n",
    "    print(\"Failed to connect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used to train the decision tree is different from the characteristics of the eth accounts so I had to make fake metadata to validate the transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w3.eth.default_account = w3.eth.accounts[0]\n",
    "\n",
    "# Load AI model\n",
    "model = joblib.load('fraud_detection_model.pkl')\n",
    "\n",
    "# Example transaction metadata\n",
    "tx_metadata = {\n",
    "    'creditLimit': 500,          # Example data\n",
    "    'availableMoney': 300,       \n",
    "    'transactionAmount': 100,    \n",
    "    'posConditionCode': 1,       \n",
    "    'cardPresent': 1             \n",
    "}\n",
    "\n",
    "# Preprocess transaction data for decision tree\n",
    "transaction_features = [\n",
    "    tx_metadata['creditLimit'],        \n",
    "    tx_metadata['availableMoney'],\n",
    "    tx_metadata['transactionAmount'],  \n",
    "    tx_metadata['posConditionCode'],  \n",
    "    tx_metadata['cardPresent']         \n",
    "]\n",
    "\n",
    "tx_metadata.get('availableMoney', 0)\n",
    "\n",
    "\n",
    "# Predict fraud\n",
    "is_fraud = model.predict([transaction_features])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define payer and payee\n",
    "payer_address = w3.eth.accounts[0]\n",
    "#account that will send the funds and deploy the contract.\n",
    "payee_address = w3.eth.accounts[1]\n",
    "#account that will receive the funds if the transaction is not flagged as fraudulent.\n",
    "w3.eth.default_account = payer_address\n",
    "#Sets the default account (payer_address) for transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the contract\n",
    "Escrow = w3.eth.contract(abi=contract_interface['abi'], bytecode=contract_interface['bin'])\n",
    "# w3.eth.contract(): Creates a Python object representing the smart contract.\n",
    "# abi: Specifies how to interact with the contract (function names, parameters, etc.).\n",
    "# bytecode: The compiled binary code of the contract.\n",
    "\n",
    "tx_hash = Escrow.constructor(payee_address).transact({'value': Web3.to_wei(1, 'ether')})\n",
    "# constructor(payee_address): Calls the contractâ€™s constructor, passing payee_address as an argument.\n",
    "# transact({'value': Web3.to_wei(1, 'ether')}):\n",
    "# Sends 1 Ether from the default_account to deploy the contract.\n",
    "# The value field specifies the amount of Ether sent with the transaction.\n",
    "tx_receipt = w3.eth.wait_for_transaction_receipt(tx_hash)\n",
    "\n",
    "# Ensure deployment was successful\n",
    "if not tx_receipt:\n",
    "    print(\"Deployment failed. No transaction receipt received.\")\n",
    "else:\n",
    "    contract_address = tx_receipt.contractAddress\n",
    "    # Ethereum address of the newly deployed contract.\n",
    "    print(f\"Contract deployed at {contract_address}\")\n",
    "\n",
    "# Interact with the contract\n",
    "Escrow = w3.eth.contract(address=contract_address, abi=contract_interface['abi'])\n",
    "\n",
    "# Example: Fraud detection integration\n",
    "if is_fraud:\n",
    "    tx_hash = Escrow.functions.reportFraud().transact({'from': w3.eth.default_account})\n",
    "    print(\"Fraud reported. Funds not released.\")\n",
    "else:\n",
    "    tx_hash = Escrow.functions.releaseFunds().transact({'from': w3.eth.default_account})\n",
    "    print(\"Funds released to payee.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgentTester",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
